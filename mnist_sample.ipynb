{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# img = Image.open('../../ml_data/mnist_train/0/img_1.jpg')\n",
    "# img_data = np.array(img)\n",
    "# print(img_data)\n",
    "# print(img_data.shape)\n",
    "# plt.imshow(img_data, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Show an sample digit.\n",
    "'''\n",
    "def show_sample_digit():\n",
    "    img = Image.open('../../ml_data/mnist_train/0/img_1.jpg')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Performs onehot-encodings for every digit (0 to 9).\n",
    "'''\n",
    "def encode_onehot(pos, n_rows):\n",
    "    # 10 classes (digit 0 to 9)\n",
    "    y_onehot = [0] * 10\n",
    "    # create onehot-encodings for digit (i - 1)\n",
    "    y_onehot[pos] = 1\n",
    "    y_onehots = [y_onehot] * n_rows\n",
    "    # convert python list to numpy array\n",
    "    # as keras requires numpy array\n",
    "    return np.array(y_onehots)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "'''\n",
    "Prepare data.\n",
    "'''\n",
    "def prep_data(paths):\n",
    "    for i in range(len(paths)):\n",
    "        data = read_img_data(paths[i])\n",
    "\n",
    "        try:\n",
    "            x = np.concatenate((x, data))\n",
    "        except:\n",
    "            x = data          \n",
    "\n",
    "        # construct the onehot-encodings for a digit's data\n",
    "        y_onehots = encode_onehot(i, data.shape[0])\n",
    "        try:\n",
    "            y = np.concatenate((y, y_onehots))\n",
    "        except:\n",
    "            y = y_onehots           \n",
    "\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         paths\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../../ml_data/mnist_train/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m prep_data(paths)\n\u001b[0;32m---> 11\u001b[0m x_train, y_train \u001b[39m=\u001b[39m prep_train_data()\n",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m, in \u001b[0;36mprep_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m      8\u001b[0m     paths\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../../ml_data/mnist_train/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m---> 10\u001b[0m \u001b[39mreturn\u001b[39;00m prep_data(paths)\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mprep_data\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprep_data\u001b[39m(paths):\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(paths)):\n\u001b[0;32m----> 6\u001b[0m         data \u001b[39m=\u001b[39m read_img_data(paths[i])\n\u001b[1;32m      8\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m             x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((x, data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_img_data' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Prepare train data.\n",
    "'''\n",
    "def prep_train_data():\n",
    "    paths = []\n",
    "\n",
    "    for i in range(10):\n",
    "        paths.append('../../ml_data/mnist_train/{}/'.format(i))\n",
    "\n",
    "    return prep_data(paths)\n",
    "\n",
    "'''\n",
    "Prepare test data.\n",
    "'''\n",
    "def prep_test_data():\n",
    "    paths = []\n",
    "\n",
    "    for i in range(10):\n",
    "        paths.append('../../ml_data/mnist_test/{}/'.format(i))\n",
    "\n",
    "    return prep_data(paths)\n",
    "\n",
    "'''\n",
    "Create our model\n",
    "'''\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32,\n",
    "        kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))    \n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "'''\n",
    "Train our model.\n",
    "'''\n",
    "def train_model(model, x_train, y_train):\n",
    "    model.fit(x=x_train, y=y_train, epochs=1)    \n",
    "\n",
    "'''\n",
    "Test our model.\n",
    "'''\n",
    "def test_model(model, x_test, y_test):\n",
    "    return model.evaluate(x=x_test, y=y_test)\n",
    "\n",
    "'''\n",
    "Save our model.\n",
    "'''\n",
    "def save_model(model, path):\n",
    "    model.save(path)\n",
    "\n",
    "'''\n",
    "Load our model.\n",
    "'''\n",
    "def load_model(path):\n",
    "    return tf.keras.models.load_model(path)\n",
    "\n",
    "'''\n",
    "Main program.\n",
    "'''\n",
    "def main():\n",
    "    # create our CNN model\n",
    "    model = create_model()\n",
    "\n",
    "    # fetch training data and onehot-encoded labels\n",
    "    x_train, y_train = prep_train_data()\n",
    "    \n",
    "    # normalize x_train to be between [0, 1]\n",
    "    train_model(model, x_train/255, y_train)\n",
    "\n",
    "    # showing how we can save our trained model\n",
    "    save_model(model, '../../ml_data/mnist_saved_model')\n",
    "    \n",
    "    # showing how we can load our trained model\n",
    "    model = load_model('../../ml_data/mnist_saved_model')\n",
    "\n",
    "    # normalize y_train to be between [0, 1]\n",
    "    x_test, y_test = prep_test_data()\n",
    "\n",
    "    # test how well our model performs against data\n",
    "    # that it has not seen before\n",
    "    test_model(model, x_test/255, y_test)\n",
    "\n",
    "\n",
    "# running via \"python mnist_sample.py\"\n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prepare test data.\n",
    "'''\n",
    "def prep_test_data():\n",
    "    paths = []\n",
    "\n",
    "    for i in range(10):\n",
    "        paths.append('../../ml_data/mnist_test/{}/'.format(i))\n",
    "\n",
    "    return prep_data(paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create our model\n",
    "'''\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32,\n",
    "        kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))    \n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Train our model.\n",
    "'''\n",
    "def train_model(model, x_train, y_train):\n",
    "    model.fit(x=x_train, y=y_train, epochs=1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Test our model.\n",
    "'''\n",
    "def test_model(model, x_test, y_test):\n",
    "    return model.evaluate(x=x_test, y=y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save our model.\n",
    "'''\n",
    "def save_model(model, path):\n",
    "    model.save(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load our model.\n",
    "'''\n",
    "def load_model(path):\n",
    "    return tf.keras.models.load_model(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# running via \"python mnist_sample.py\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m   main()\n",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[39m=\u001b[39m create_model()\n\u001b[1;32m      8\u001b[0m \u001b[39m# fetch training data and onehot-encoded labels\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m x_train, y_train \u001b[39m=\u001b[39m prep_train_data()\n\u001b[1;32m     11\u001b[0m \u001b[39m# normalize x_train to be between [0, 1]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m train_model(model, x_train\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m, y_train)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mprep_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m      8\u001b[0m     paths\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../../ml_data/mnist_train/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m---> 10\u001b[0m \u001b[39mreturn\u001b[39;00m prep_data(paths)\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mprep_data\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprep_data\u001b[39m(paths):\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(paths)):\n\u001b[0;32m----> 6\u001b[0m         data \u001b[39m=\u001b[39m read_img_data(paths[i])\n\u001b[1;32m      8\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m             x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((x, data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_img_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Main program.\n",
    "'''\n",
    "def main():\n",
    "    # create our CNN model\n",
    "    model = create_model()\n",
    "\n",
    "    # fetch training data and onehot-encoded labels\n",
    "    x_train, y_train = prep_train_data()\n",
    "    \n",
    "    # normalize x_train to be between [0, 1]\n",
    "    train_model(model, x_train/255, y_train)\n",
    "\n",
    "    # showing how we can save our trained model\n",
    "    save_model(model, '../../ml_data/mnist_saved_model')\n",
    "    \n",
    "    # showing how we can load our trained model\n",
    "    model = load_model('../../ml_data/mnist_saved_model')\n",
    "\n",
    "    # normalize y_train to be between [0, 1]\n",
    "    x_test, y_test = prep_test_data()\n",
    "\n",
    "    # test how well our model performs against data\n",
    "    # that it has not seen before\n",
    "    test_model(model, x_test/255, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "194439896e2e70bd9825da6ce00ecad8aaee198f2edf1414a456886314b0a83d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
